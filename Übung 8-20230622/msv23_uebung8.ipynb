{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92194704",
   "metadata": {},
   "source": [
    "# MSV / SS 2023 - Übung 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d292f",
   "metadata": {},
   "source": [
    "Wir verwenden texte aus Harry Potter Bücher. \n",
    "\n",
    "Quellen:\n",
    "\n",
    "(Daten) https://github.com/amisha-jodhani/text-generator-harry-potter\n",
    "\n",
    "(Code) https://www.nltk.org/api/nltk.lm.html und https://www.kaggle.com/code/alvations/n-gram-language-model-with-nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6ec7d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import re \n",
    "\n",
    "all_files = os.listdir(\"harrypotter/\")   # imagine you're one directory above test dir\n",
    "\n",
    "hp_corpus = \"\"\n",
    "\n",
    "for filename in all_files:\n",
    "    if \".txt\" in filename:\n",
    "        with open(\"harrypotter/\"+filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "            hp_corpus += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd109f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1: The Other Minister\\nIt was nearing midnight and the Prime Minister was sitting alone in his office, reading a long memo that was slipping through his brain without leaving the slightest trace of meaning behind. He was waiting for a call from the President of a far distant country, and betw'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_corpus[0:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952b7fd5",
   "metadata": {},
   "source": [
    "## 8.1 Sprachgenerierung mit N-Grams\n",
    "\n",
    "#### 1. Tokenization und padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88f3029b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f2c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = [list(map(str.lower, word_tokenize(sent))) \n",
    "                  for sent in sent_tokenize(hp_corpus)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67aa999b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['how', 'on', 'earth', 'was', 'his', 'government', 'supposed', 'to', 'have', 'stopped', 'that', 'bridge', 'collapsing', '?'], ['it', 'was', 'outrageous', 'for', 'anybody', 'to', 'suggest', 'that', 'they', 'were', 'not', 'spending', 'enough', 'on', 'bridges', '.'], ['the', 'bridge', 'was', 'fewer', 'than', 'ten', 'years', 'old', ',', 'and', 'the', 'best', 'experts', 'were', 'at', 'a', 'loss', 'to', 'explain', 'why', 'it', 'had', 'snapped', 'cleanly', 'in', 'two', ',', 'sending', 'a', 'dozen', 'cars', 'into', 'the', 'watery', 'depths', 'of', 'the', 'river', 'below', '.'], ['and', 'how', 'dare', 'anyone', 'suggest', 'that', 'it', 'was', 'lack', 'of', 'policemen', 'that', 'had', 'resulted', 'in', 'those', 'two', 'very', 'nasty', 'and', 'well-publicized', 'murders', '?'], ['or', 'that', 'the', 'government', 'should', 'have', 'somehow', 'foreseen', 'the', 'freak', 'hurricane', 'in', 'the', 'west', 'country', 'that', 'had', 'caused', 'so', 'much', 'damage', 'to', 'both', 'people', 'and', 'property', '?'], ['and', 'was', 'it', 'his', 'fault', 'that', 'one', 'of', 'his', 'junior', 'ministers', ',', 'herbert', 'chorley', ',', 'had', 'chosen', 'this', 'week', 'to', 'act', 'so', 'peculiarly', 'that', 'he', 'was', 'now', 'going', 'to', 'be', 'spending', 'a', 'lot', 'more', 'time', 'with', 'his', 'family', '?'], ['``', 'a', 'grim', 'mood', 'has', 'gripped', 'the', 'country', ',', \"''\", 'the', 'opponent', 'had', 'concluded', ',', 'barely', 'concealing', 'his', 'own', 'broad', 'grin', '.'], ['and', 'unfortunately', ',', 'this', 'was', 'perfectly', 'true', '.'], ['the', 'prime', 'minister', 'felt', 'it', 'himself', ';', 'people', 'really', 'did', 'seem', 'more', 'miserable', 'than', 'usual', '.'], ['even', 'the', 'weather', 'was', 'dismal', ';', 'all', 'this', 'chilly', 'mist', 'in', 'the', 'middle', 'of', 'july', '...']]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_text[5:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89701f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80740"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14f57c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80660"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split = len(tokenized_text)-int(len(tokenized_text)/1000)\n",
    "split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d8375d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "n = 3\n",
    "\n",
    "training_ngrams, padded_sentences_training = padded_everygram_pipeline(n, tokenized_text[:split])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4011cd82",
   "metadata": {},
   "source": [
    "#### Was haben wir gemacht? Ein Beispiel mit 1 Satz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5f36ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['how',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'was',\n",
       " 'his',\n",
       " 'government',\n",
       " 'supposed',\n",
       " 'to',\n",
       " 'have',\n",
       " 'stopped',\n",
       " 'that',\n",
       " 'bridge',\n",
       " 'collapsing',\n",
       " '?']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "75749388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<s>',), ('<s>', 'how'), ('how',), ('how', 'on'), ('on',), ('on', 'earth'), ('earth',), ('earth', 'was'), ('was',), ('was', 'his'), ('his',), ('his', 'government'), ('government',), ('government', 'supposed'), ('supposed',), ('supposed', 'to'), ('to',), ('to', 'have'), ('have',), ('have', 'stopped'), ('stopped',), ('stopped', 'that'), ('that',), ('that', 'bridge'), ('bridge',), ('bridge', 'collapsing'), ('collapsing',), ('collapsing', '?'), ('?',), ('?', '</s>'), ('</s>',)]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'how',\n",
       " 'on',\n",
       " 'earth',\n",
       " 'was',\n",
       " 'his',\n",
       " 'government',\n",
       " 'supposed',\n",
       " 'to',\n",
       " 'have',\n",
       " 'stopped',\n",
       " 'that',\n",
       " 'bridge',\n",
       " 'collapsing',\n",
       " '?',\n",
       " '</s>']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_1s, padded_sentences_1s = padded_everygram_pipeline(2, tokenized_text[5:6])\n",
    "\n",
    "for ngramlize_sent in ngrams_1s:\n",
    "    print(list(ngramlize_sent))\n",
    "    print()\n",
    "    \n",
    "list(padded_sentences_1s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97d151",
   "metadata": {},
   "source": [
    "#### 2. Training eines 3-Gramm-Modells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2bc0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import MLE\n",
    "model = MLE(n)  # Inisialisierung des MLE Modells, n=3, am Anfang ist das Lexicon (vocab) leer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31b462cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "633f8d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Vocabulary with cutoff=1 unk_label='<UNK>' and 25823 items>\n"
     ]
    }
   ],
   "source": [
    "model.fit(training_ngrams, padded_sentences_training)\n",
    "print(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f342769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25823"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee97109f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NgramCounter with 3 ngram orders and 4896339 ngrams>\n"
     ]
    }
   ],
   "source": [
    "print(model.counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4a3e7",
   "metadata": {},
   "source": [
    "#### Ngrams mit \"Potter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b087c0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18014"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts['harry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b244d6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['harry']]['potter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4c04c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02065060508493394"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('potter', 'harry'.split())  # P('potter'|'harry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63b3c39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['boy']]['who'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b37c088f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.counts[['boy', 'who']]['lived'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38413a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score('lived', 'boy who'.split())  # P('lived'|'boy who')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61746c3",
   "metadata": {},
   "source": [
    "#### 3. Generierung\n",
    "\n",
    "Diese Funktion macht den generierten Text besser lesbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14dced5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "detokenize = TreebankWordDetokenizer().detokenize\n",
    "\n",
    "def generate_sent(model, num_words, random_seed=42):\n",
    "    \"\"\"\n",
    "    :param model: An ngram language model from `nltk.lm.model`.\n",
    "    :param num_words: Max no. of words to generate.\n",
    "    :param random_seed: Seed value for random.\n",
    "    \"\"\"\n",
    "    content = []\n",
    "    for token in model.generate(num_words, random_seed=random_seed):\n",
    "        if token == '<s>':\n",
    "            continue\n",
    "        if token == '</s>':\n",
    "            break\n",
    "        content.append(token)\n",
    "    return detokenize(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42518869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the security i've got no proof at all.\n",
      "3 re going to happen before it sped across the stone floor for a moment later, to the bathroom, echoing voice.\n",
      "were walking.\n",
      "\"i might never come and stay .\" voldemort moved slowly toward the concealed printing press blocking the stairs, slipped on his back to politeness, \"sooner you ask me, we ’ ll be all that hap-pened between james and lily.\n",
      "a double-decker bus rumbled by and large, old-fashioned, red-brick department store called purge & dowse ltd.\n",
      "in the same way as your brain and you resorted to crude and badly judged meas-ures such as he was standing behind quirrell.\n",
      "shaggy head behind him, lost his powers, had come to tell me it was always ill at the staff table set at a terrible scream.\n",
      "his black eyes gleaming.\n",
      "\n",
      "cup.\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(generate_sent(model, 10000, random_seed=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "78e6a09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "itself, if i remember it well!\"\n",
      ", pettigrew, and she walked back to azkaban...but too late: there was only their heads, incapable of saying it for months.\"\n",
      "at once from the distant bangs of battle, enter the triwizard tournament.\n",
      "\"i'm \"\" aren ’ t, and dobby thinks, and there was a little patience with it, sibyll?\"\n",
      "this is not touched by the neck to ankles to the sitting room, where it would suffice.\n",
      "a large display near the fence, looking alarmed, and whispered, bristling with anger.\n",
      "harry, shaking her magnificent head.\n",
      ", feeling around in my bag!\"\n",
      "face.\n",
      "\"well, my scar hurt when nobody has seen it alive.\n"
     ]
    }
   ],
   "source": [
    "for i in range(42, 52):\n",
    "    print(generate_sent(model, 10000, random_seed=i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec27042",
   "metadata": {},
   "source": [
    "## 8.2 Sprachgenerierung mit RNN Netze"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a94d55a",
   "metadata": {},
   "source": [
    "\n",
    "https://santiviquez-harry-potter-rnn-app-bjb9w6.streamlit.app/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32790b3",
   "metadata": {},
   "source": [
    "## 8.3 Sprachgenerierung mit LSTM Netze (heute: nur Trainingsdatenvorbereitung)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dba84a8",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1lKOwObRmjANWHhNHx4Urk4H7UZFYG74U?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cd9046",
   "metadata": {},
   "source": [
    "## 8.4 Textklassifizierung mit LSTM Netze (SpaCy und Keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126ef67",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1Am5IuGfGUSFIk17ZBaER4d4v14E3o7B0?usp=sharing\n",
    "\n",
    "basiert auf: \n",
    "- Duygu Altinok, Mastering Spacy, Chapt 8 - Code und Daten: https://github.com/PacktPublishing/Mastering-spaCy/tree/main/Chapter08 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
