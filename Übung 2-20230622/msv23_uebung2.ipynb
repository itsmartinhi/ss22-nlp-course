{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ccf074",
   "metadata": {},
   "source": [
    "# MSV / SS 2023 - Übung 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a041ce1",
   "metadata": {},
   "source": [
    "## 2.1 Erste Schritte mit Spacy\n",
    "\n",
    "Am Anfang müssen wir Spacy importieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e7c270d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1328f8d4",
   "metadata": {},
   "source": [
    "SpaCy bietet für die deutsche Sprache und die englische Sprache bereits trainierte Modelle verschieden große an, die mit unterschiedlichen Textdaten trainiert wurden:\n",
    "\n",
    "- Englisch: en_core_web_sm, en_core_web_md, en_core_web_lg, en_core_web_trf (sehe auch  https://spacy.io/models/en )\n",
    "- Deutsch: de_core_news_sm, de_core_news_md, de_core_news_lg, de_dep_news_trf (sehe auch https://spacy.io/models/de )\n",
    "\n",
    "Also bitte vorher New ‣ Terminal auswahlen und die Sprachmodelle unterladen \n",
    "```\n",
    "python -m spacy download en_core_web_sm\n",
    "python -m spacy download de_core_news_sm\n",
    "```\n",
    "\n",
    "Es handelt sich um bereits trainierte statistische Modelle. Je nach Modell unterscheiden sich die Textanalysen in Genauigkeit und Geschwindigkeit. \n",
    "\n",
    "Wir laden die kleinste Modelle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e58fcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en = spacy.load(\"en_core_web_sm\") \n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "nlp_en_bigger = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6602e877",
   "metadata": {},
   "source": [
    "Mit ``spacy.load()`` erzeugen wir eine Instanz der Klasse ``Language``\n",
    "\n",
    "<img src=\"https://spacy.io/images/architecture.svg\" alt=\"SpaCy architecture\" width=\"350\" />\n",
    "\n",
    "Jede Instanz der Klasse ``Language`` enthält eine sprachspezifische Verarbeitungspipeline\n",
    "\n",
    "<img src=\"https://spacy.io/images/pipeline.svg\" alt=\"SpaCy architecture\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7004c9",
   "metadata": {},
   "source": [
    "Wenn man ein Text mit dem nlp-Objekt verarbeitet, erstellt Spacy ein Doc objekt (eine Python-Sequenz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cca61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "beispiel_1 = \"Das Mädchen sah den Jungen mit dem Fernglas.\"\n",
    "doc = nlp_de(beispiel_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc915317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Das\n",
      "Mädchen\n",
      "sah\n",
      "den\n",
      "Jungen\n",
      "mit\n",
      "dem\n",
      "Fernglas\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text) # attribute: text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92adc869",
   "metadata": {},
   "source": [
    "### Visualisierung des Outputs der Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b422836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Morph</th>\n",
       "      <th>Dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Das</td>\n",
       "      <td>der</td>\n",
       "      <td>DET</td>\n",
       "      <td>ART</td>\n",
       "      <td>[Case=Nom, Definite=Def, Gender=Neut, Number=S...</td>\n",
       "      <td>nk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mädchen</td>\n",
       "      <td>Mädchen</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>[Case=Nom, Gender=Neut, Number=Sing]</td>\n",
       "      <td>sb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sah</td>\n",
       "      <td>sehen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>[Mood=Ind, Number=Sing, Person=3, Tense=Past, ...</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>den</td>\n",
       "      <td>der</td>\n",
       "      <td>DET</td>\n",
       "      <td>ART</td>\n",
       "      <td>[Case=Acc, Definite=Def, Gender=Masc, Number=S...</td>\n",
       "      <td>nk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jungen</td>\n",
       "      <td>Junge</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>[Case=Acc, Gender=Masc, Number=Sing]</td>\n",
       "      <td>oa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mit</td>\n",
       "      <td>mit</td>\n",
       "      <td>ADP</td>\n",
       "      <td>APPR</td>\n",
       "      <td>[]</td>\n",
       "      <td>mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dem</td>\n",
       "      <td>der</td>\n",
       "      <td>DET</td>\n",
       "      <td>ART</td>\n",
       "      <td>[Case=Dat, Definite=Def, Gender=Masc, Number=S...</td>\n",
       "      <td>nk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fernglas</td>\n",
       "      <td>Fernglas</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>[Case=Dat, Gender=Masc, Number=Sing]</td>\n",
       "      <td>nk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>.</td>\n",
       "      <td>--</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>$.</td>\n",
       "      <td>[]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token     Lemma    POS    Tag  \\\n",
       "0       Das       der    DET    ART   \n",
       "1   Mädchen   Mädchen   NOUN     NN   \n",
       "2       sah     sehen   VERB  VVFIN   \n",
       "3       den       der    DET    ART   \n",
       "4    Jungen     Junge   NOUN     NN   \n",
       "5       mit       mit    ADP   APPR   \n",
       "6       dem       der    DET    ART   \n",
       "7  Fernglas  Fernglas   NOUN     NN   \n",
       "8         .        --  PUNCT     $.   \n",
       "\n",
       "                                               Morph    Dep  \n",
       "0  [Case=Nom, Definite=Def, Gender=Neut, Number=S...     nk  \n",
       "1               [Case=Nom, Gender=Neut, Number=Sing]     sb  \n",
       "2  [Mood=Ind, Number=Sing, Person=3, Tense=Past, ...   ROOT  \n",
       "3  [Case=Acc, Definite=Def, Gender=Masc, Number=S...     nk  \n",
       "4               [Case=Acc, Gender=Masc, Number=Sing]     oa  \n",
       "5                                                 []     mo  \n",
       "6  [Case=Dat, Definite=Def, Gender=Masc, Number=S...     nk  \n",
       "7               [Case=Dat, Gender=Masc, Number=Sing]     nk  \n",
       "8                                                 []  punct  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame({\"Token\": [token.text for token in doc],\n",
    "              \"Lemma\": [token.lemma_ for token in doc],\n",
    "              \"POS\": [token.pos_ for token in doc],\n",
    "              \"Tag\": [token.tag_ for token in doc],\n",
    "              \"Morph\": [list(token.morph) for token in doc],\n",
    "              \"Dep\": [token.dep_ for token in doc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c340d9df",
   "metadata": {},
   "source": [
    "### Visualisierung mit displaCy\n",
    "\n",
    "Dependenzbeziehungen zwischen den Wörtern werden typischerweise als gerichtete, etikettierte Kanten dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c53b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"de\" id=\"8fc49d04e836465d84febdd3b6fba162-0\" class=\"displacy\" width=\"1250\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Das</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">Mädchen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">sah</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">den</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">Jungen</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">mit</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">dem</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">Fernglas.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8fc49d04e836465d84febdd3b6fba162-0-0\" stroke-width=\"2px\" d=\"M62,227.0 62,202.0 194.0,202.0 194.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8fc49d04e836465d84febdd3b6fba162-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8fc49d04e836465d84febdd3b6fba162-0-1\" stroke-width=\"2px\" d=\"M212,227.0 212,202.0 344.0,202.0 344.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8fc49d04e836465d84febdd3b6fba162-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">sb</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M212,229.0 L208,221.0 216,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8fc49d04e836465d84febdd3b6fba162-0-2\" stroke-width=\"2px\" d=\"M512,227.0 512,202.0 644.0,202.0 644.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8fc49d04e836465d84febdd3b6fba162-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,229.0 L508,221.0 516,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8fc49d04e836465d84febdd3b6fba162-0-3\" stroke-width=\"2px\" d=\"M362,227.0 362,177.0 647.0,177.0 647.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8fc49d04e836465d84febdd3b6fba162-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">oa</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M647.0,229.0 L651.0,221.0 643.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8fc49d04e836465d84febdd3b6fba162-0-4\" stroke-width=\"2px\" d=\"M362,227.0 362,152.0 800.0,152.0 800.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8fc49d04e836465d84febdd3b6fba162-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mo</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M800.0,229.0 L804.0,221.0 796.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8fc49d04e836465d84febdd3b6fba162-0-5\" stroke-width=\"2px\" d=\"M962,227.0 962,202.0 1094.0,202.0 1094.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8fc49d04e836465d84febdd3b6fba162-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M962,229.0 L958,221.0 966,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8fc49d04e836465d84febdd3b6fba162-0-6\" stroke-width=\"2px\" d=\"M812,227.0 812,177.0 1097.0,177.0 1097.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8fc49d04e836465d84febdd3b6fba162-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nk</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1097.0,229.0 L1101.0,221.0 1093.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "#displacy.render(doc, style=\"dep\")\n",
    "displacy.render(doc, style=\"dep\", options = {\"compact\": True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1cb8f0",
   "metadata": {},
   "source": [
    "Die Dependency Labels sind in der Dokumentation des Sprachmodells definiert: https://spacy.io/models/de\n",
    "Oder alternativ kann mann auch die spacy-explain Funktion verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a5efc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noun kernel element\n",
      "subject\n",
      "accusative object\n",
      "modifier\n"
     ]
    }
   ],
   "source": [
    "print(spacy.explain(\"nk\"))\n",
    "print(spacy.explain(\"sb\"))\n",
    "print(spacy.explain(\"oa\"))\n",
    "print(spacy.explain(\"mo\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa546b7",
   "metadata": {},
   "source": [
    "## 2.2 Tokenization und Lemmatization mit Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b30e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_lyrics = \"I can't get no satisfaction, 'Cause I try, and I try, and I try, and I try\"\n",
    "doc = nlp_en(my_lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2109514b",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa23325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'ca', \"n't\", 'get', 'no', 'satisfaction', ',', \"'Cause\", 'I', 'try', ',', 'and', 'I', 'try', ',', 'and', 'I', 'try', ',', 'and', 'I', 'try']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print tokens\n",
    "tokens = [token.text\n",
    "         for token in doc]\n",
    "print(tokens) \n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936f6b01",
   "metadata": {},
   "source": [
    "\"can't\" wurde in zwei Token aufgeteilt: Spacy erkennt sowohl das Wurzelverb als auch die Negation\n",
    "\n",
    "#### Ohne Satzzeichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e640a558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'ca', \"n't\", 'get', 'no', 'satisfaction', \"'Cause\", 'I', 'try', 'and', 'I', 'try', 'and', 'I', 'try', 'and', 'I', 'try']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [token.text\n",
    "         for token in doc\n",
    "         if not token.is_punct]\n",
    "print(tokens)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58969842",
   "metadata": {},
   "source": [
    "#### Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "600fe3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_string = \"I've tried a thousand times! Lemme see.\"\n",
    "doc = nlp_en(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f28259fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Morph</th>\n",
       "      <th>Dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[Case=Nom, Number=Sing, Person=1, PronType=Prs]</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'ve</td>\n",
       "      <td>'ve</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>[Mood=Ind, Tense=Pres, VerbForm=Fin]</td>\n",
       "      <td>aux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tried</td>\n",
       "      <td>try</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBN</td>\n",
       "      <td>[Aspect=Perf, Tense=Past, VerbForm=Part]</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DT</td>\n",
       "      <td>[Definite=Ind, PronType=Art]</td>\n",
       "      <td>quantmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thousand</td>\n",
       "      <td>thousand</td>\n",
       "      <td>NUM</td>\n",
       "      <td>CD</td>\n",
       "      <td>[NumType=Card]</td>\n",
       "      <td>nummod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>times</td>\n",
       "      <td>time</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>[Number=Plur]</td>\n",
       "      <td>npadvmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>[PunctType=Peri]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lemme</td>\n",
       "      <td>Lemme</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>NNP</td>\n",
       "      <td>[Number=Sing]</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>see</td>\n",
       "      <td>see</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VBP</td>\n",
       "      <td>[Tense=Pres, VerbForm=Fin]</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>[PunctType=Peri]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Token     Lemma    POS  Tag  \\\n",
       "0         I         I   PRON  PRP   \n",
       "1       've       've    AUX  VBP   \n",
       "2     tried       try   VERB  VBN   \n",
       "3         a         a    DET   DT   \n",
       "4  thousand  thousand    NUM   CD   \n",
       "5     times      time   NOUN  NNS   \n",
       "6         !         !  PUNCT    .   \n",
       "7     Lemme     Lemme  PROPN  NNP   \n",
       "8       see       see   VERB  VBP   \n",
       "9         .         .  PUNCT    .   \n",
       "\n",
       "                                             Morph       Dep  \n",
       "0  [Case=Nom, Number=Sing, Person=1, PronType=Prs]     nsubj  \n",
       "1             [Mood=Ind, Tense=Pres, VerbForm=Fin]       aux  \n",
       "2         [Aspect=Perf, Tense=Past, VerbForm=Part]      ROOT  \n",
       "3                     [Definite=Ind, PronType=Art]  quantmod  \n",
       "4                                   [NumType=Card]    nummod  \n",
       "5                                    [Number=Plur]  npadvmod  \n",
       "6                                 [PunctType=Peri]     punct  \n",
       "7                                    [Number=Sing]     nsubj  \n",
       "8                       [Tense=Pres, VerbForm=Fin]      ROOT  \n",
       "9                                 [PunctType=Peri]     punct  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Token\": [token.text for token in doc],\n",
    "              \"Lemma\": [token.lemma_ for token in doc],\n",
    "              \"POS\": [token.pos_ for token in doc],\n",
    "              \"Tag\": [token.tag_ for token in doc],\n",
    "              \"Morph\": [list(token.morph) for token in doc],\n",
    "              \"Dep\": [token.dep_ for token in doc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282942e7",
   "metadata": {},
   "source": [
    "#### Erklärung der Regeln des Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a83e070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t SPECIAL-1\n",
      "'ve \t SPECIAL-2\n",
      "tried \t TOKEN\n",
      "a \t TOKEN\n",
      "thousand \t TOKEN\n",
      "times \t TOKEN\n",
      "! \t SUFFIX\n",
      "Lemme \t TOKEN\n",
      "see \t TOKEN\n",
      ". \t SUFFIX\n"
     ]
    }
   ],
   "source": [
    "tok_exp = nlp_en.tokenizer.explain(new_string)\n",
    "for t in tok_exp:\n",
    "    print(t[1], \"\\t\", t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ac253",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://spacy.io/images/tokenization.svg\" alt=\"SpaCy architecture\" width=\"350\" />\n",
    "\n",
    "\n",
    "#### Eine neue Regel für den Tokenizer\n",
    "\n",
    "(<i>Lemme</i> als <i>Lem</i> <i>me</i>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3875dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH\n",
    "special_case = [{ORTH: \"lem\"}, {ORTH: \"me\"}]\n",
    "nlp_en.tokenizer.add_special_case(\"lemme\", special_case)\n",
    "special_case = [{ORTH: \"Lem\"}, {ORTH: \"me\"}]\n",
    "nlp_en.tokenizer.add_special_case(\"Lemme\", special_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df5627a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t SPECIAL-1\n",
      "'ve \t SPECIAL-2\n",
      "tried \t TOKEN\n",
      "a \t TOKEN\n",
      "thousand \t TOKEN\n",
      "times \t TOKEN\n",
      "! \t SUFFIX\n",
      "Lem \t SPECIAL-1\n",
      "me \t SPECIAL-2\n",
      "see \t TOKEN\n",
      ". \t SUFFIX\n"
     ]
    }
   ],
   "source": [
    "tok_exp = nlp_en.tokenizer.explain(new_string)\n",
    "for t in tok_exp:\n",
    "    print(t[1], \"\\t\", t[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09de8ab4",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4f2f158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'ve\", 'tried', 'a', 'thousand', 'times', 'Lemme', 'see']\n",
      "['I', \"'ve\", 'try', 'a', 'thousand', 'time', 'Lemme', 'see']\n"
     ]
    }
   ],
   "source": [
    "tokens = [token.text\n",
    "         for token in doc\n",
    "         if not token.is_punct]\n",
    "\n",
    "lemmata = [token.lemma_ \n",
    "           for token in doc\n",
    "           if not token.is_punct]\n",
    "\n",
    "print(tokens[0:17])\n",
    "print(lemmata[0:17])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0390f7",
   "metadata": {},
   "source": [
    "### Lemmatizer: nur Lookup?\n",
    "\n",
    "\"Bitte\" kann ein Adverb (<i>Bitte rufen Sie mich an</i> oder ein Substantiv (<i>Ich hätte eine Bitte an Sie</i>) sein. Wie geht das Lemmatizer damit um?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f7fbe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Morph</th>\n",
       "      <th>Dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bitte</td>\n",
       "      <td>bitte</td>\n",
       "      <td>ADV</td>\n",
       "      <td>ADV</td>\n",
       "      <td>[]</td>\n",
       "      <td>mo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rufen</td>\n",
       "      <td>rufen</td>\n",
       "      <td>VERB</td>\n",
       "      <td>VVFIN</td>\n",
       "      <td>[Mood=Ind, Number=Plur, Person=3, Tense=Pres, ...</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sie</td>\n",
       "      <td>sie</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PPER</td>\n",
       "      <td>[Case=Nom, Number=Plur, Person=3, PronType=Prs]</td>\n",
       "      <td>sb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mich</td>\n",
       "      <td>mich</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PPER</td>\n",
       "      <td>[Case=Acc, Number=Sing, Person=1, PronType=Prs]</td>\n",
       "      <td>oa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "      <td>ADP</td>\n",
       "      <td>PTKVZ</td>\n",
       "      <td>[]</td>\n",
       "      <td>svp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token  Lemma   POS    Tag  \\\n",
       "0  Bitte  bitte   ADV    ADV   \n",
       "1  rufen  rufen  VERB  VVFIN   \n",
       "2    Sie    sie  PRON   PPER   \n",
       "3   mich   mich  PRON   PPER   \n",
       "4     an     an   ADP  PTKVZ   \n",
       "\n",
       "                                               Morph   Dep  \n",
       "0                                                 []    mo  \n",
       "1  [Mood=Ind, Number=Plur, Person=3, Tense=Pres, ...  ROOT  \n",
       "2    [Case=Nom, Number=Plur, Person=3, PronType=Prs]    sb  \n",
       "3    [Case=Acc, Number=Sing, Person=1, PronType=Prs]    oa  \n",
       "4                                                 []   svp  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitte_noun = \"Bitte rufen Sie mich an\"\n",
    "bitte_noun_doc = nlp_de(bitte_noun)\n",
    "\n",
    "pd.DataFrame({\"Token\": [token.text for token in bitte_noun_doc],\n",
    "              \"Lemma\": [token.lemma_ for token in bitte_noun_doc],\n",
    "              \"POS\": [token.pos_ for token in bitte_noun_doc],\n",
    "              \"Tag\": [token.tag_ for token in bitte_noun_doc],\n",
    "              \"Morph\": [list(token.morph) for token in bitte_noun_doc],\n",
    "              \"Dep\": [token.dep_ for token in bitte_noun_doc]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a243a5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Morph</th>\n",
       "      <th>Dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ich</td>\n",
       "      <td>ich</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PPER</td>\n",
       "      <td>[Case=Nom, Number=Sing, Person=1, PronType=Prs]</td>\n",
       "      <td>sb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hätte</td>\n",
       "      <td>haben</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VAFIN</td>\n",
       "      <td>[Mood=Sub, Number=Sing, Person=1, Tense=Past, ...</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eine</td>\n",
       "      <td>ein</td>\n",
       "      <td>DET</td>\n",
       "      <td>ART</td>\n",
       "      <td>[Case=Acc, Definite=Ind, Gender=Fem, Number=Si...</td>\n",
       "      <td>nk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bitte</td>\n",
       "      <td>Bitte</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>NN</td>\n",
       "      <td>[Case=Acc, Gender=Fem, Number=Sing]</td>\n",
       "      <td>oa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "      <td>ADP</td>\n",
       "      <td>APPR</td>\n",
       "      <td>[]</td>\n",
       "      <td>mnr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sie</td>\n",
       "      <td>sie</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PPER</td>\n",
       "      <td>[Case=Acc, Number=Sing, Person=3, PronType=Prs]</td>\n",
       "      <td>nk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Token  Lemma   POS    Tag  \\\n",
       "0    Ich    ich  PRON   PPER   \n",
       "1  hätte  haben   AUX  VAFIN   \n",
       "2   eine    ein   DET    ART   \n",
       "3  Bitte  Bitte  NOUN     NN   \n",
       "4     an     an   ADP   APPR   \n",
       "5    Sie    sie  PRON   PPER   \n",
       "\n",
       "                                               Morph   Dep  \n",
       "0    [Case=Nom, Number=Sing, Person=1, PronType=Prs]    sb  \n",
       "1  [Mood=Sub, Number=Sing, Person=1, Tense=Past, ...  ROOT  \n",
       "2  [Case=Acc, Definite=Ind, Gender=Fem, Number=Si...    nk  \n",
       "3                [Case=Acc, Gender=Fem, Number=Sing]    oa  \n",
       "4                                                 []   mnr  \n",
       "5    [Case=Acc, Number=Sing, Person=3, PronType=Prs]    nk  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitte_part = \"Ich hätte eine Bitte an Sie\"\n",
    "bitte_part_doc = nlp_de(bitte_part)\n",
    "\n",
    "pd.DataFrame({\"Token\": [token.text for token in bitte_part_doc],\n",
    "              \"Lemma\": [token.lemma_ for token in bitte_part_doc],\n",
    "              \"POS\": [token.pos_ for token in bitte_part_doc],\n",
    "              \"Tag\": [token.tag_ for token in bitte_part_doc],\n",
    "              \"Morph\": [list(token.morph) for token in bitte_part_doc],\n",
    "              \"Dep\": [token.dep_ for token in bitte_part_doc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d50bf21",
   "metadata": {},
   "source": [
    "#### Eine neue Regel für den Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17e6ab35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Morph</th>\n",
       "      <th>Dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They</td>\n",
       "      <td>they</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[Case=Nom, Number=Plur, Person=3, PronType=Prs]</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'re</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>[Mood=Ind, Tense=Pres, VerbForm=Fin]</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there</td>\n",
       "      <td>there</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>[PronType=Dem]</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>[]</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>[]</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>[PunctType=Peri]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[Case=Nom, Number=Sing, Person=1, PronType=Prs]</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'ve</td>\n",
       "      <td>'ve</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>[Mood=Ind, Tense=Pres, VerbForm=Fin]</td>\n",
       "      <td>aux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>been</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBN</td>\n",
       "      <td>[Tense=Past, VerbForm=Part]</td>\n",
       "      <td>ccomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>there</td>\n",
       "      <td>there</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>[PronType=Dem]</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>[PunctType=Comm]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[Case=Nom, Gender=Neut, Number=Sing, Person=3,...</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'s</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>[Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>[Degree=Pos]</td>\n",
       "      <td>acomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>[PunctType=Peri]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Token  Lemma    POS  Tag  \\\n",
       "0    They   they   PRON  PRP   \n",
       "1     're     be    AUX  VBP   \n",
       "2   there  there    ADV   RB   \n",
       "3   right  right    ADV   RB   \n",
       "4     now    now    ADV   RB   \n",
       "5       .      .  PUNCT    .   \n",
       "6       I      I   PRON  PRP   \n",
       "7     've    've    AUX  VBP   \n",
       "8    been     be    AUX  VBN   \n",
       "9   there  there    ADV   RB   \n",
       "10      ,      ,  PUNCT    ,   \n",
       "11     it     it   PRON  PRP   \n",
       "12     's     be    AUX  VBZ   \n",
       "13  great  great    ADJ   JJ   \n",
       "14      !      !  PUNCT    .   \n",
       "\n",
       "                                                Morph     Dep  \n",
       "0     [Case=Nom, Number=Plur, Person=3, PronType=Prs]   nsubj  \n",
       "1                [Mood=Ind, Tense=Pres, VerbForm=Fin]    ROOT  \n",
       "2                                      [PronType=Dem]  advmod  \n",
       "3                                                  []  advmod  \n",
       "4                                                  []  advmod  \n",
       "5                                    [PunctType=Peri]   punct  \n",
       "6     [Case=Nom, Number=Sing, Person=1, PronType=Prs]   nsubj  \n",
       "7                [Mood=Ind, Tense=Pres, VerbForm=Fin]     aux  \n",
       "8                         [Tense=Past, VerbForm=Part]   ccomp  \n",
       "9                                      [PronType=Dem]  advmod  \n",
       "10                                   [PunctType=Comm]   punct  \n",
       "11  [Case=Nom, Gender=Neut, Number=Sing, Person=3,...   nsubj  \n",
       "12  [Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...    ROOT  \n",
       "13                                       [Degree=Pos]   acomp  \n",
       "14                                   [PunctType=Peri]   punct  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions = \"They're there right now. I've been there, it's great!\"\n",
    "contractions_doc = nlp_en(contractions)\n",
    "\n",
    "pd.DataFrame({\"Token\": [token.text for token in contractions_doc],\n",
    "              \"Lemma\": [token.lemma_ for token in contractions_doc],\n",
    "              \"POS\": [token.pos_ for token in contractions_doc],\n",
    "              \"Tag\": [token.tag_ for token in contractions_doc],\n",
    "              \"Morph\": [list(token.morph) for token in contractions_doc],\n",
    "              \"Dep\": [token.dep_ for token in contractions_doc]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02c05cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_en.get_pipe(\"attribute_ruler\").add([[{\"TEXT\": \"'ve\"}]], {\"LEMMA\": \"have\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ad781be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Morph</th>\n",
       "      <th>Dep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They</td>\n",
       "      <td>they</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[Case=Nom, Number=Plur, Person=3, PronType=Prs]</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'re</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>[Mood=Ind, Tense=Pres, VerbForm=Fin]</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there</td>\n",
       "      <td>there</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>[PronType=Dem]</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>right</td>\n",
       "      <td>right</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>[]</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>now</td>\n",
       "      <td>now</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>[]</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>[PunctType=Peri]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[Case=Nom, Number=Sing, Person=1, PronType=Prs]</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'ve</td>\n",
       "      <td>have</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBP</td>\n",
       "      <td>[Mood=Ind, Tense=Pres, VerbForm=Fin]</td>\n",
       "      <td>aux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>been</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBN</td>\n",
       "      <td>[Tense=Past, VerbForm=Part]</td>\n",
       "      <td>ccomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>there</td>\n",
       "      <td>there</td>\n",
       "      <td>ADV</td>\n",
       "      <td>RB</td>\n",
       "      <td>[PronType=Dem]</td>\n",
       "      <td>advmod</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>,</td>\n",
       "      <td>[PunctType=Comm]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PRON</td>\n",
       "      <td>PRP</td>\n",
       "      <td>[Case=Nom, Gender=Neut, Number=Sing, Person=3,...</td>\n",
       "      <td>nsubj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>'s</td>\n",
       "      <td>be</td>\n",
       "      <td>AUX</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>[Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...</td>\n",
       "      <td>ROOT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>great</td>\n",
       "      <td>great</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>[Degree=Pos]</td>\n",
       "      <td>acomp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>.</td>\n",
       "      <td>[PunctType=Peri]</td>\n",
       "      <td>punct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Token  Lemma    POS  Tag  \\\n",
       "0    They   they   PRON  PRP   \n",
       "1     're     be    AUX  VBP   \n",
       "2   there  there    ADV   RB   \n",
       "3   right  right    ADV   RB   \n",
       "4     now    now    ADV   RB   \n",
       "5       .      .  PUNCT    .   \n",
       "6       I      I   PRON  PRP   \n",
       "7     've   have    AUX  VBP   \n",
       "8    been     be    AUX  VBN   \n",
       "9   there  there    ADV   RB   \n",
       "10      ,      ,  PUNCT    ,   \n",
       "11     it     it   PRON  PRP   \n",
       "12     's     be    AUX  VBZ   \n",
       "13  great  great    ADJ   JJ   \n",
       "14      !      !  PUNCT    .   \n",
       "\n",
       "                                                Morph     Dep  \n",
       "0     [Case=Nom, Number=Plur, Person=3, PronType=Prs]   nsubj  \n",
       "1                [Mood=Ind, Tense=Pres, VerbForm=Fin]    ROOT  \n",
       "2                                      [PronType=Dem]  advmod  \n",
       "3                                                  []  advmod  \n",
       "4                                                  []  advmod  \n",
       "5                                    [PunctType=Peri]   punct  \n",
       "6     [Case=Nom, Number=Sing, Person=1, PronType=Prs]   nsubj  \n",
       "7                [Mood=Ind, Tense=Pres, VerbForm=Fin]     aux  \n",
       "8                         [Tense=Past, VerbForm=Part]   ccomp  \n",
       "9                                      [PronType=Dem]  advmod  \n",
       "10                                   [PunctType=Comm]   punct  \n",
       "11  [Case=Nom, Gender=Neut, Number=Sing, Person=3,...   nsubj  \n",
       "12  [Mood=Ind, Number=Sing, Person=3, Tense=Pres, ...    ROOT  \n",
       "13                                       [Degree=Pos]   acomp  \n",
       "14                                   [PunctType=Peri]   punct  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions_doc = nlp_en(contractions)\n",
    "pd.DataFrame({\"Token\": [token.text for token in contractions_doc],\n",
    "              \"Lemma\": [token.lemma_ for token in contractions_doc],\n",
    "              \"POS\": [token.pos_ for token in contractions_doc],\n",
    "              \"Tag\": [token.tag_ for token in contractions_doc],\n",
    "              \"Morph\": [list(token.morph) for token in contractions_doc],\n",
    "              \"Dep\": [token.dep_ for token in contractions_doc]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983f2c0",
   "metadata": {},
   "source": [
    "## 2.3 Korpora\n",
    "\n",
    "Um datenbasierte Darstellungen der Bedeutung eines Wortes zu erstellen, benötigen wir einen <b>Korpus</b>.</br>\n",
    "</br>\n",
    "Ein Textkorpus ist eine Sammlung von Texten einer bestimmten Sprache, die „repräsentativ“ im statistischen Sinne für der Sprache betrachten wird.\n",
    "</br>\n",
    "Deswegen importieren wir das Modul ``nltk`` und das Brown corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "232f0159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     /Users/alessandra/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"brown\")\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51f3d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb16867",
   "metadata": {},
   "source": [
    "#### Größe des Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4a6d082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161192"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_size = len(brown.words())\n",
    "brown_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8266aa70",
   "metadata": {},
   "source": [
    "#### Wortschatzgröße des Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b3e1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56057"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown_voc_size = len(set(brown.words()))\n",
    "brown_voc_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760d26a3",
   "metadata": {},
   "source": [
    "## 2.4 Maximum-Likelihood-Schätzung aus relativer Häufgkeit in Korpus\n",
    "\n",
    "P(the|is in charge of) = C(is in charge of the) / C(is in charge of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "505701da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of 'is in charge of': 2\n",
      "Frequency of 'is in charge of the': 0\n"
     ]
    }
   ],
   "source": [
    "fourgrams = Counter(list(ngrams(brown.words(),4)))\n",
    "fivegrams = Counter(list(ngrams(brown.words(),5)))\n",
    "\n",
    "print(\"Frequency of 'is in charge of': \" + str(fourgrams[('is', 'in', 'charge', 'of')]))\n",
    "print(\"Frequency of 'is in charge of the': \" + str(fivegrams[('is', 'in', 'charge', 'of', 'the')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc40e4e3",
   "metadata": {},
   "source": [
    "#### Markov-Annahme\n",
    "\n",
    "P(the|in charge of) = C(in charge of the) / C(in charge of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8feb491b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of 'in charge of the': 8\n",
      "Frequency of 'in charge of': 16\n",
      "P of 'the'|'in charge of': 0.5\n"
     ]
    }
   ],
   "source": [
    "trigrams = Counter(list(ngrams(brown.words(),3)))\n",
    "\n",
    "print(\"Frequency of 'in charge of the': \" + str(fourgrams[('in', 'charge', 'of', 'the')]))\n",
    "print(\"Frequency of 'in charge of': \" + str(trigrams[('in', 'charge', 'of')]))\n",
    "print(\"P of 'the'|'in charge of': \" + str(fourgrams[('in', 'charge', 'of', 'the')]/trigrams[('in', 'charge', 'of')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2909cd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of 'charge of': 29\n",
      "Frequency of 'charge of the': 12\n",
      "P of 'the'|'charge of': 0.41379310344827586\n"
     ]
    }
   ],
   "source": [
    "bigrams = Counter(list(ngrams(brown.words(),2)))\n",
    "\n",
    "print(\"Frequency of 'charge of': \" + str(bigrams[('charge', 'of')]))\n",
    "print(\"Frequency of 'charge of the': \" + str(trigrams[('charge', 'of', 'the')]))\n",
    "print(\"P of 'the'|'charge of': \" + str(trigrams[('charge', 'of', 'the')]/bigrams[('charge', 'of')]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d041cd32",
   "metadata": {},
   "source": [
    "## 2.5 N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7539ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef3ead0",
   "metadata": {},
   "source": [
    "#### Zerograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba232805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('Chinese')  = 1.7838985318515083e-05\n"
     ]
    }
   ],
   "source": [
    "P_Chinese = 1/brown_voc_size\n",
    "print(\"P('Chinese')  = \" + str(P_Chinese))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0497d085",
   "metadata": {},
   "source": [
    "c.a. 0.000018\n",
    "\n",
    "#### Unigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "deb3d204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 62713, ',': 58334, '.': 49346, 'of': 36080, 'and': 27915, 'to': 25732, 'a': 21881, 'in': 19536, 'that': 10237, 'is': 10011, ...})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import FreqDist\n",
    "brown_FD = FreqDist(brown.words())\n",
    "brown_FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f371bc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_Chinese = brown_FD['Chinese']\n",
    "F_Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83682981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P('Chinese')  = 4.822630538274463e-05\n"
     ]
    }
   ],
   "source": [
    "P_Chinese = F_Chinese/brown_size\n",
    "print(\"P('Chinese')  = \" + str(P_Chinese))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d393f5d2",
   "metadata": {},
   "source": [
    "c.a. 0.000048\n",
    "\n",
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62658b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'I'),\n",
       " ('I', 'want'),\n",
       " ('want', 'to'),\n",
       " ('to', 'eat'),\n",
       " ('eat', 'Chinese'),\n",
       " ('Chinese', 'food'),\n",
       " ('food', '</s>')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.util import bigrams\n",
    "#list(bigrams(brown.words()))\n",
    "my_lyrics = \"<s> I want to eat Chinese food </s>\"\n",
    "my_lyrics_tokenized = re.split(\" \",my_lyrics)\n",
    "list(bigrams(my_lyrics_tokenized))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2d028",
   "metadata": {},
   "source": [
    "## 2.5 Einfache Sprachmodellierung mit N-Grammen: Berkeley Restaurant Project Data (Jurafsky & Martin, Chapter 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ecc88204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I': 2533, 'want': 927, 'to': 2417, 'eat': 746, 'chinese': 158, 'food': 1093, 'lunch': 341, 'spend': 278}\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "brp_unigrams = {'I': 2533,\n",
    "                'want': 927,\n",
    "                'to': 2417,\n",
    "                'eat' : 746,\n",
    "                'chinese' : 158,\n",
    "                'food' : 1093,\n",
    "                'lunch': 341,\n",
    "                'spend': 278}\n",
    "\n",
    "print(brp_unigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cd713c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          I  want   to  eat  chinese  food  lunch  spend\n",
      "I         5   827    0    9        0     0      0      2\n",
      "want      2     0  608    1        6     6      5      1\n",
      "to        2     0    4  686        2     0      6    211\n",
      "eat       0     0    2    0       16     2     42      0\n",
      "chinese   1     0    0    0        0    82      1      0\n",
      "food     15     0   15    0        1     4      0      0\n",
      "lunch     2     0    0    0        0     1      0      0\n",
      "spend     1     0    1    0        0     0      0      0\n"
     ]
    }
   ],
   "source": [
    "brp_big_fq = [(5, 827, 0, 9, 0, 0, 0, 2),\n",
    "              (2, 0, 608, 1, 6, 6, 5, 1),\n",
    "              (2, 0, 4, 686, 2, 0, 6, 211),\n",
    "              (0, 0, 2, 0, 16, 2, 42, 0),\n",
    "              (1, 0, 0, 0, 0, 82, 1, 0),\n",
    "              (15, 0, 15, 0, 1, 4, 0, 0),\n",
    "              (2, 0, 0, 0, 0, 1, 0, 0),\n",
    "              (1, 0, 1, 0, 0, 0, 0, 0)]  \n",
    "\n",
    "brp_bigrams = pd.DataFrame(brp_big_fq, columns = ['I' , 'want', 'to' , 'eat', 'chinese', 'food', 'lunch', 'spend'], index=['I' , 'want', 'to' , 'eat', 'chinese', 'food', 'lunch', 'spend'])\n",
    "\n",
    "print(brp_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7c582",
   "metadata": {},
   "source": [
    "##### Zeilen = (I, I), (I, want), (I, to), (I, eat)... \n",
    "##### P(Chinese food) >> P(food Chinese)\n",
    "\n",
    "Normalisierung der Häufigkeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bab83f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>want</th>\n",
       "      <th>to</th>\n",
       "      <th>eat</th>\n",
       "      <th>chinese</th>\n",
       "      <th>food</th>\n",
       "      <th>lunch</th>\n",
       "      <th>spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.001974</td>\n",
       "      <td>0.32649</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.655879</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.283823</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.087298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021448</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.518987</td>\n",
       "      <td>0.006329</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.013724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.003660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002933</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend</th>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                I     want        to       eat   chinese      food     lunch  \\\n",
       "I        0.001974  0.32649  0.000000  0.003553  0.000000  0.000000  0.000000   \n",
       "want     0.002157  0.00000  0.655879  0.001079  0.006472  0.006472  0.005394   \n",
       "to       0.000827  0.00000  0.001655  0.283823  0.000827  0.000000  0.002482   \n",
       "eat      0.000000  0.00000  0.002681  0.000000  0.021448  0.002681  0.056300   \n",
       "chinese  0.006329  0.00000  0.000000  0.000000  0.000000  0.518987  0.006329   \n",
       "food     0.013724  0.00000  0.013724  0.000000  0.000915  0.003660  0.000000   \n",
       "lunch    0.005865  0.00000  0.000000  0.000000  0.000000  0.002933  0.000000   \n",
       "spend    0.003597  0.00000  0.003597  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            spend  \n",
       "I        0.000790  \n",
       "want     0.001079  \n",
       "to       0.087298  \n",
       "eat      0.000000  \n",
       "chinese  0.000000  \n",
       "food     0.000000  \n",
       "lunch    0.000000  \n",
       "spend    0.000000  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brp_bigrams_norm = brp_bigrams.div(brp_unigrams, axis='index')\n",
    "brp_bigrams_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b010a595",
   "metadata": {},
   "source": [
    "#### Einige vorgegebene Wahrscheinlichkeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5d7794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_s_i = 0.25 # P(i|<s>) = 0.25\n",
    "P_want_english = 0.0011 #P(english|want) = 0.0011\n",
    "P_english_food = 0.5 # P(food|english) = 0.5 \n",
    "P_food_s = 0.68 # P(</s>|food) = 0.68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b844a39",
   "metadata": {},
   "source": [
    "#### P(\\<s\\> i want english food \\</s\\>) vs. P(\\<s\\> i want chinese food \\</s\\>)\n",
    "P(\\<s\\> i want english food \\</s\\>) = P(i|\\<s\\>)\\*P(want|i)\\*P(english|want)\\*P(food|english)\\*P(\\</s\\>|food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "813c1f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(<s> i want english food </s>) = 0.000031\n"
     ]
    }
   ],
   "source": [
    "# P(<s> i want english food </s>) = P(i|<s>)*P(want|i)*P(english|want)*P(food|english)*P(</s>|food)\n",
    "P_eng = P_s_i * brp_bigrams_norm.loc['I','want'] * P_want_english * P_english_food * P_food_s\n",
    "print(\"P(<s> i want english food </s>) = \" + '{:f}'.format(P_eng)) # no scientific notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c75da79",
   "metadata": {},
   "source": [
    "P(\\<s\\> i want chinese food \\</s\\>) = P(i|\\<s\\>)\\*P(want|i)\\*P(chinese|want)\\*P(food|chinese)\\*P(\\</s\\>|food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "db7eb73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(<s> i want chinese food </s>) = 0.000186\n"
     ]
    }
   ],
   "source": [
    "# P(<s> i want chinese food </s>) = P(i|<s>)*P(want|i)*P(chinese|want)*P(food|english)*P(</s>|food)\n",
    "P_chi = P_s_i * brp_bigrams_norm.loc['I','want'] * brp_bigrams_norm.loc['want','chinese']  * brp_bigrams_norm.loc['chinese','food'] * P_food_s\n",
    "print(\"P(<s> i want chinese food </s>) = \" + '{:f}'.format(P_chi)) # no scientific notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1603d99",
   "metadata": {},
   "source": [
    "### Problem: Underflow ###\n",
    "Kleine Zahlen, Rundungsprobleme</br>\n",
    "−→ Alles im log-Raum berechnet</br>\n",
    "</br>\n",
    "log P(\\<s\\> i want english food \\</s\\>) = log P(i|\\<s\\>) + log P(want|i) + log P(english|want) + log P(food|english) + log P (\\</s\\>|food)</br>\n",
    "log P(\\<s\\> i want chinese food \\</s\\>) = log P(i|\\<s\\>) + log P(want|i) + log P(chinese|want) + log P(food|chinese) +  log P (\\</s\\>|food)</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "62afa6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log P(<s> i want english food </s>) = -10.396904076647616\n",
      "P(<s> i want english food </s>) = exp(log P(<s> i want english food </s>) = 0.000031\n"
     ]
    }
   ],
   "source": [
    "logP_eng = np.log(P_s_i) + np.log(brp_bigrams_norm.loc['I','want']) + np.log(P_want_english) + np.log(P_english_food) + np.log(P_food_s)\n",
    "print(\"log P(<s> i want english food </s>) = \" + str(logP_eng)) \n",
    "P_eng = np.exp(logP_eng)\n",
    "print(\"P(<s> i want english food </s>) = exp(log P(<s> i want english food </s>) = \" + '{:f}'.format(P_eng)) # no scientific notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "42f0db9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log P(<s> i want chinese food </s>) = -8.587381679010372\n",
      "P(<s> i want chinese food </s>) = exp(log P(<s> i want chinese food </s>) = 0.000186\n"
     ]
    }
   ],
   "source": [
    "logP_chi = np.log(P_s_i) + np.log(brp_bigrams_norm.loc['I','want']) + np.log(brp_bigrams_norm.loc['want','chinese']) + np.log(brp_bigrams_norm.loc['chinese','food']) + np.log(P_food_s)\n",
    "print(\"log P(<s> i want chinese food </s>) = \" + str(logP_chi)) \n",
    "P_chi = np.exp(logP_chi)\n",
    "print(\"P(<s> i want chinese food </s>) = exp(log P(<s> i want chinese food </s>) = \" + '{:f}'.format(P_chi)) # no scientific notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59290a38",
   "metadata": {},
   "source": [
    "### Problem: ungesehene Daten\n",
    "\n",
    "P(\\<s\\> i want dutch food \\</s\\>) = P(i|\\<s\\>)\\*P(want|i)\\*P(dutch|want)\\*P(food|dutch)\\*P(\\</s\\>|food)<br/>\n",
    "P(food|dutch) = 0<br/>\n",
    "P(\\<s\\> i want dutch food \\</s\\>) = 0<br/>\n",
    "\n",
    "#### Laplace Smoothing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d970e987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>want</th>\n",
       "      <th>to</th>\n",
       "      <th>eat</th>\n",
       "      <th>chinese</th>\n",
       "      <th>food</th>\n",
       "      <th>lunch</th>\n",
       "      <th>spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>5</td>\n",
       "      <td>827</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>686</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          I  want   to  eat  chinese  food  lunch  spend\n",
       "I         5   827    0    9        0     0      0      2\n",
       "want      2     0  608    1        6     6      5      1\n",
       "to        2     0    4  686        2     0      6    211\n",
       "eat       0     0    2    0       16     2     42      0\n",
       "chinese   1     0    0    0        0    82      1      0\n",
       "food     15     0   15    0        1     4      0      0\n",
       "lunch     2     0    0    0        0     1      0      0\n",
       "spend     1     0    1    0        0     0      0      0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brp_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cafb40de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>want</th>\n",
       "      <th>to</th>\n",
       "      <th>eat</th>\n",
       "      <th>chinese</th>\n",
       "      <th>food</th>\n",
       "      <th>lunch</th>\n",
       "      <th>spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>6</td>\n",
       "      <td>828</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>609</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>687</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          I  want   to  eat  chinese  food  lunch  spend\n",
       "I         6   828    1   10        1     1      1      3\n",
       "want      3     1  609    2        7     7      6      2\n",
       "to        3     1    5  687        3     1      7    212\n",
       "eat       1     1    3    1       17     3     43      1\n",
       "chinese   2     1    1    1        1    83      2      1\n",
       "food     16     1   16    1        2     5      1      1\n",
       "lunch     3     1    1    1        1     2      1      1\n",
       "spend     2     1    2    1        1     1      1      1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brp_bigrams_laplace = brp_bigrams.copy()\n",
    "brp_bigrams_laplace += 1\n",
    "brp_bigrams_laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d61294c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 2533,\n",
       " 'want': 927,\n",
       " 'to': 2417,\n",
       " 'eat': 746,\n",
       " 'chinese': 158,\n",
       " 'food': 1093,\n",
       " 'lunch': 341,\n",
       " 'spend': 278}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brp_unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73c34a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I': 3979,\n",
       " 'want': 2373,\n",
       " 'to': 3863,\n",
       " 'eat': 2192,\n",
       " 'chinese': 1604,\n",
       " 'food': 2539,\n",
       " 'lunch': 1787,\n",
       " 'spend': 1724}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = 1446\n",
    "brp_unigrams_laplace = brp_unigrams.copy()\n",
    "for k, v in brp_unigrams_laplace.items():\n",
    "    brp_unigrams_laplace[k] += W\n",
    "brp_unigrams_laplace  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c186277d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>want</th>\n",
       "      <th>to</th>\n",
       "      <th>eat</th>\n",
       "      <th>chinese</th>\n",
       "      <th>food</th>\n",
       "      <th>lunch</th>\n",
       "      <th>spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.208092</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.000843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.177841</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.054880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.007755</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>0.019617</td>\n",
       "      <td>0.000456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.051746</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.000623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend</th>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000580</td>\n",
       "      <td>0.000580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                I      want        to       eat   chinese      food     lunch  \\\n",
       "I        0.001508  0.208092  0.000251  0.002513  0.000251  0.000251  0.000251   \n",
       "want     0.001264  0.000421  0.256637  0.000843  0.002950  0.002950  0.002528   \n",
       "to       0.000777  0.000259  0.001294  0.177841  0.000777  0.000259  0.001812   \n",
       "eat      0.000456  0.000456  0.001369  0.000456  0.007755  0.001369  0.019617   \n",
       "chinese  0.001247  0.000623  0.000623  0.000623  0.000623  0.051746  0.001247   \n",
       "food     0.006302  0.000394  0.006302  0.000394  0.000788  0.001969  0.000394   \n",
       "lunch    0.001679  0.000560  0.000560  0.000560  0.000560  0.001119  0.000560   \n",
       "spend    0.001160  0.000580  0.001160  0.000580  0.000580  0.000580  0.000580   \n",
       "\n",
       "            spend  \n",
       "I        0.000754  \n",
       "want     0.000843  \n",
       "to       0.054880  \n",
       "eat      0.000456  \n",
       "chinese  0.000623  \n",
       "food     0.000394  \n",
       "lunch    0.000560  \n",
       "spend    0.000580  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brp_bigrams_norm_laplace = brp_bigrams_laplace.div(brp_unigrams_laplace, axis='index')\n",
    "brp_bigrams_norm_laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9b70127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "brp_bigrams_newcounts_laplace = brp_bigrams_norm_laplace.multiply(brp_unigrams, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ce1340bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>want</th>\n",
       "      <th>to</th>\n",
       "      <th>eat</th>\n",
       "      <th>chinese</th>\n",
       "      <th>food</th>\n",
       "      <th>lunch</th>\n",
       "      <th>spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>3.82</td>\n",
       "      <td>527.10</td>\n",
       "      <td>0.64</td>\n",
       "      <td>6.37</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>1.17</td>\n",
       "      <td>0.39</td>\n",
       "      <td>237.90</td>\n",
       "      <td>0.78</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.73</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1.88</td>\n",
       "      <td>0.63</td>\n",
       "      <td>3.13</td>\n",
       "      <td>429.84</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.63</td>\n",
       "      <td>4.38</td>\n",
       "      <td>132.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.34</td>\n",
       "      <td>5.79</td>\n",
       "      <td>1.02</td>\n",
       "      <td>14.63</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>8.18</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>6.89</td>\n",
       "      <td>0.43</td>\n",
       "      <td>6.89</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.15</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend</th>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            I    want      to     eat  chinese  food  lunch   spend\n",
       "I        3.82  527.10    0.64    6.37     0.64  0.64   0.64    1.91\n",
       "want     1.17    0.39  237.90    0.78     2.73  2.73   2.34    0.78\n",
       "to       1.88    0.63    3.13  429.84     1.88  0.63   4.38  132.64\n",
       "eat      0.34    0.34    1.02    0.34     5.79  1.02  14.63    0.34\n",
       "chinese  0.20    0.10    0.10    0.10     0.10  8.18   0.20    0.10\n",
       "food     6.89    0.43    6.89    0.43     0.86  2.15   0.43    0.43\n",
       "lunch    0.57    0.19    0.19    0.19     0.19  0.38   0.19    0.19\n",
       "spend    0.32    0.16    0.32    0.16     0.16  0.16   0.16    0.16"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_col = brp_bigrams_newcounts_laplace.select_dtypes(include=['float64']) # float columns only\n",
    "for col in float_col.columns.values:\n",
    "    brp_bigrams_newcounts_laplace[col] = np.round(brp_bigrams_newcounts_laplace[col], decimals=2)\n",
    "#    brp_bigrams_newcounts_laplace[col] = brp_bigrams_newcounts_laplace[col].astype('int64')\n",
    "brp_bigrams_newcounts_laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d419e16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>want</th>\n",
       "      <th>to</th>\n",
       "      <th>eat</th>\n",
       "      <th>chinese</th>\n",
       "      <th>food</th>\n",
       "      <th>lunch</th>\n",
       "      <th>spend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>5</td>\n",
       "      <td>827</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>want</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>686</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lunch</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spend</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          I  want   to  eat  chinese  food  lunch  spend\n",
       "I         5   827    0    9        0     0      0      2\n",
       "want      2     0  608    1        6     6      5      1\n",
       "to        2     0    4  686        2     0      6    211\n",
       "eat       0     0    2    0       16     2     42      0\n",
       "chinese   1     0    0    0        0    82      1      0\n",
       "food     15     0   15    0        1     4      0      0\n",
       "lunch     2     0    0    0        0     1      0      0\n",
       "spend     1     0    1    0        0     0      0      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brp_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7ff65",
   "metadata": {},
   "source": [
    "## Hausaufgaben\n",
    "\n",
    "### Übung 1\n",
    "\n",
    "- \"on the other hand\"\n",
    "- \"on the other end\"\n",
    "\n",
    "Welche Wortfolge ist die wahrscheinlichste? Die Wahrscheinlichkeit mit N-grams (aus relativer Häufgkeit im Brown Korpus - Maximum-Likelihood-Schätzung) schätzen. Groß- und Kleinschreibung beachten.\n",
    "\n",
    "### Übung 2\n",
    "\n",
    "Suchen Sie nach alle Bigramme und Trigramme, die mit \"eat\" anfangen (z.B. \"eat chicken\", \"eat French fries\"), und sortieren Sie sie nach Häufigkeit. \n",
    "\n",
    "### Übung 3\n",
    "\n",
    "Wie wahrscheinlich ist \"i want chinese food\" mit Add-1-Smoothing?<br/>\n",
    "(Sie brauchen dafür auch P(i|\\<s\\>) = 0.19 and P(\\</s\\>|food) =0.40) <br/>\n",
    "<br/>\n",
    "Wie ist die Add-1-Smoothing Wahrscheinlicheit im Vergleich zur Wahrscheinlicheit ohne Smoothing?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
