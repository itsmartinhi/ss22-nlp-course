{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba5e7d1",
   "metadata": {},
   "source": [
    "# MSV / SS 2023 - Übung 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80331d",
   "metadata": {},
   "source": [
    "### 4.1 Binäre Sentiment-Klassifizierung mit Logistic Regression - Beispiel aus Jurafsky & Martin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371e1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cffd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing . It sucked me in , and it'll do the same to you .\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = (\n",
    "    \"It's hokey . There are virtually no surprises , \"\n",
    "    \"and the writing is second-rate . So why was it so enjoyable ? \"\n",
    "    \"For one thing , the cast is great . Another nice touch is the music . \"\n",
    "    \"I was overcome with the urge to get off the couch and start dancing . \"\n",
    "    \"It sucked me in , and it'll do the same to you .\"\n",
    "        )\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c96f0e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       features  values  weights\n",
      "0                 # pos. Wörter    3.00      2.5\n",
      "1                 # neg. Wörter    2.00     -5.0\n",
      "2              'no' im Dokument    1.00     -1.2\n",
      "3  # 1. oder 2. Person Pronomen    3.00      0.5\n",
      "4               '!' im Dokument    0.00      2.0\n",
      "5               log(word count)    4.19      0.7\n"
     ]
    }
   ],
   "source": [
    "sentiment_feat = [(\"# pos. Wörter\", 3, 2.5),\n",
    "                  (\"# neg. Wörter\", 2, -5),\n",
    "              (\"'no' im Dokument\", 1, -1.2),\n",
    "             (\"# 1. oder 2. Person Pronomen\", 3, 0.5),\n",
    "             (\"'!' im Dokument\", 0, 2), \n",
    "             (\"log(word count)\", 4.19, 0.7)]  \n",
    "\n",
    "\n",
    "sentiment_feat = pd.DataFrame(sentiment_feat, columns = ['features' , 'values', 'weights'])\n",
    "\n",
    "print(sentiment_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace30dc",
   "metadata": {},
   "source": [
    "#### Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64dc475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f8a7b",
   "metadata": {},
   "source": [
    "#### \"Testing\": Die Sigmoid als Klassifizierungsfunktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31e9b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de08499",
   "metadata": {},
   "source": [
    "#### P(+|x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a40f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z =  0.8330000000000001\n",
      "P(+|x) =  0.6969888901292717\n"
     ]
    }
   ],
   "source": [
    "z = sum(sentiment_feat['values']*sentiment_feat['weights'])+bias\n",
    "print('z = ',z)\n",
    "print('P(+|x) = ',sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87acab4c",
   "metadata": {},
   "source": [
    "#### P(-|x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5725534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(-|x) =  0.3030111098707283\n"
     ]
    }
   ],
   "source": [
    "print('P(-|x) = ',1-sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03b394",
   "metadata": {},
   "source": [
    "### 4.2 Training\n",
    "#### Kreuzentropie als Verlustfunktion\n",
    "\n",
    "Ziel: \n",
    "* kleinere Verlust, wenn das Modell richtig geantwortet hat \n",
    "* größerer Verlust, wenn das Model falsch verstanden hat\n",
    "\n",
    "$L(\\hat{y},y) = -[y \\log \\hat{y} + (1 - y) \\log (1 - \\hat{y})]$\n",
    "\n",
    "mit $y = 1$: $L(\\hat{y},y) = -  \\log \\hat{y}  $\n",
    "\n",
    "\n",
    "mit $y = 0$: $L(\\hat{y},y) = -\\log (1 - \\hat{y})$\n",
    "\n",
    "\n",
    "(und nicht vergessen: $\\hat{y} = \\sigma(w \\cdot x + b)$\n",
    "\n",
    "####  Verlust für $\\hat{y} = 0.70$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "128290db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3000584796176432"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = sum(sentiment_feat['values']*sentiment_feat['weights'])+bias\n",
    "pred_y = sigmoid(z)\n",
    "verlust = -(np.log(pred_y))\n",
    "verlust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba5ba39",
   "metadata": {},
   "source": [
    "Und wenn die richtige Antwort $y = 0$ ist und $\\hat{y} = 0.70$?\n",
    "\n",
    "$L(\\hat{y},y) = -[ (1 - y) \\log (1 - \\hat{y})]$\n",
    "\n",
    "####  Verlust für $\\hat{y} = 0.70$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81647c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3500584796176431"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verlust = -(np.log(1-pred_y))\n",
    "verlust"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a4ca4",
   "metadata": {},
   "source": [
    "### Gradient Descent: 1 Schritt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "529f619c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"It's hokey . There are virtually no surprises , and the writing is second-rate . So why was it so enjoyable ? For one thing , the cast is great . Another nice touch is the music . I was overcome with the urge to get off the couch and start dancing . It sucked me in , and it'll do the same to you .\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d527075b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            features  values  weights\n",
      "0  x1: # pos. Wörter       3        0\n",
      "1  x2: # neg. Wörter       2        0\n"
     ]
    }
   ],
   "source": [
    "sentiment_feat_s = [(\"x1: # pos. Wörter\", 3, 0),\n",
    "                  (\"x2: # neg. Wörter\", 2, 0)]  \n",
    "\n",
    "\n",
    "sentiment_feat_s = pd.DataFrame(sentiment_feat_s, columns = ['features' , 'values', 'weights'])\n",
    "\n",
    "print(sentiment_feat_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5591c5e8",
   "metadata": {},
   "source": [
    "#### Bias & Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74a29897",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 0\n",
    "learn_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2272ada",
   "metadata": {},
   "source": [
    "#### Gradient Vektor (3-dim)\n",
    "\n",
    "$y = 1$\n",
    "\n",
    "$\\nabla_{w,b} = \\begin{bmatrix} (\\sigma(w \\cdot x + b)-y)x_1 \\\\ (\\sigma(w \\cdot x + b)-y)x_2 \\\\ \\sigma(w \\cdot x + b)-y\\end{bmatrix}  $ \n",
    "\n",
    "(1) Klassifizierungsfunktion für geschätzen y (y = 0)\n",
    "\n",
    "$ =  \n",
    "\\begin{bmatrix} (\\sigma(0)-1)x_1 \\\\ (\\sigma(0)-1)x_2 \\\\ \\sigma(0)-1\\end{bmatrix} = \\begin{bmatrix} (0.5-1)x_1 \\\\ (0.5-1)x_2 \\\\ 0.5-1\\end{bmatrix}  $ \n",
    "\n",
    "(2) Verlust & Gradient Vektor\n",
    "\n",
    "$= \\begin{bmatrix} -0.5 x_1 \\\\ -0.5 x_2 \\\\ -0.5 \\end{bmatrix} = \n",
    "\\begin{bmatrix} -1.5 \\\\ -1.0 \\\\ -0.5 \\end{bmatrix}  =\n",
    "\\begin{bmatrix} -1.5 \\\\ -1.0 \\\\ -0.5 \\end{bmatrix} $ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15580a93",
   "metadata": {},
   "source": [
    "#### Wie sehen die neue Parametern nach 1 Schritt aus?\n",
    "\n",
    "Learning Rate\n",
    "\n",
    "$\\eta = 0.1$\n",
    "\n",
    "Gradient Vector\n",
    "\n",
    "$\\begin{bmatrix} -1.5 \\\\ -1.0 \\\\ -0.5\\end{bmatrix}$\n",
    "\n",
    "\n",
    "Parameter update (opposite direction as gradient):\n",
    "\n",
    "$\\theta_{t+1} = \\theta_t - \\eta\\nabla L(f(x;\\theta),y)$\n",
    "\n",
    "$\\theta_{1} = \\begin{bmatrix} w_1 \\\\ w_2 \\\\ b\\end{bmatrix} - 0.1\n",
    "\\begin{bmatrix} -1.5 \\\\ -1.0 \\\\ -0.5\\end{bmatrix} =\n",
    "\\begin{bmatrix} 0 \\\\ 0 \\\\ 0\\end{bmatrix} - \n",
    "\\begin{bmatrix} -.15 \\\\ -.1 \\\\ -.05\\end{bmatrix} = \\begin{bmatrix} .15 \\\\ .1 \\\\ .05\\end{bmatrix}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b2127f",
   "metadata": {},
   "source": [
    "## Hausaufgaben\n",
    "\n",
    "### Übung 4.1\n",
    "\n",
    "Noch einen Schritt Gradient Descent berechnen, mit dem folgenden Beispiel \n",
    "\n",
    "y = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc2f964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        features  values  weights\n",
      "0  # pos. Wörter       1     0.15\n",
      "1  # neg. Wörter       4     0.10\n"
     ]
    }
   ],
   "source": [
    "bias = 0.5\n",
    "\n",
    "sentiment_feat = [(\"# pos. Wörter\", 1, .15),\n",
    "                  (\"# neg. Wörter\", 4, .1)]  \n",
    "\n",
    "sentiment_feat = pd.DataFrame(sentiment_feat, columns = ['features' , 'values', 'weights'])\n",
    "\n",
    "print(sentiment_feat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
